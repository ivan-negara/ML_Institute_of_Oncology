---
title: "timeseriesML"
output: html_document
date: "2023-12-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#libraries
``` {r}
library(fs)
library(corrplot)
library(purrr)
library(gridExtra)
library(h2o)
library(psych)
library(reshape2)
library(ggplot2)
library(dplyr)
library(tidyr)
library(readxl)
library(plotly)
library(tidyquant)
library(colorspace)
library(RColorBrewer)
library(tidyverse)
library(lubridate)
library(writexl)
library(jsonlite)
library(xts)
library(TSstudio)
library(plotly)
library(workflows)
library(parsnip)
library(recipes)
library(yardstick)
library(glmnet)
library(tidyverse)
library(tidyquant)
library(timetk) # Use >= 0.1.3, remotes::install_github("business-science/timetk")
library(rsample)
library(modeltime)
library(vip)
library(tseries)
library(forecast)
library(remotes)
library(tsibble)
library(lessR)
library(fpp3)
library(ggcorrplot)
```

### Data cleaning
```{r 2, echo=FALSE}
 imputed_spital = read.csv('Admission_Delays_pre-cleaned.csv')
imputed_spital <- imputed_spital %>% select(-X)

 
imputed_spital <- imputed_spital %>%
  dplyr::rename(Date = Data, Department = Sectie, Zile = Zile)
 imputed_spital$Date <- as.Date(imputed_spital$Date, format="%Y-%m-%d")
key_columns <- c("Department")
index_column <- "Date"

# Get the row numbers
row_numbers <- which(is_duplicate <- duplicated(imputed_spital %>% select(all_of(key_columns), all_of(index_column))) | 
          duplicated(imputed_spital %>% select(all_of(key_columns), all_of(index_column)), fromLast = TRUE))
imputed_spital <- imputed_spital[-row_numbers, ]

#create tsibble and xts

df <- as.xts(imputed_spital)
df_tsibble <- as_tsibble(imputed_spital,  index = Date, key = Department)


# Make data regularly spaced by moving every date to friday
df_standardized_date <- df_tsibble %>%
 mutate(new_date = floor_date(Date, "week") + days(5))


#  Fill in missing weeks
df_tsibble_filled <- df_standardized_date %>%
   complete(new_date = seq(min(new_date), max(new_date), by = "1 week"), fill = list(Value = 0))
df_tsibble_filled <- df_tsibble_filled %>%
  mutate(Date = new_date) %>%
  select(-new_date)

  #interpolate everything in between, remove duplicates
row_numbers <- which(is_duplicate <- duplicated(df_tsibble_filled %>% select(all_of(key_columns), all_of(index_column))) | 
          duplicated(df_tsibble_filled %>% select(all_of(key_columns), all_of(index_column)), fromLast = TRUE))
df_tsibble_filled <- df_tsibble_filled[-row_numbers, ]
df_standardized_date2 <- df_tsibble_filled %>%
 mutate(new_date = floor_date(Date, "week") + days(5))
df_tsibble_filled2 <- df_standardized_date2 %>%
   complete(new_date = seq(min(new_date), max(new_date), by = "1 week"), fill = list(Value = 0))
df_tsibble_filled2 <- df_tsibble_filled2 %>%
  mutate(Date = new_date) %>%
  select(-new_date)

df_tsibble_filled2 <- df_tsibble_filled2 %>% arrange(Department, Date)

# Group by 'Sectie' and apply na.approx within each group
df_tsibble_interpolated <- df_tsibble_filled2 %>%
  group_by(Department) %>%
  mutate(Zile = zoo::na.approx(Zile, na.rm = FALSE)) %>%
  ungroup()

df_tsibble_interpolated <- df_tsibble_interpolated %>% mutate(Zile = round(Zile, 0))

#####Clean Gyneco

# Identify the split date
split_date <- as.Date("2023-12-15")

# Separate data into two parts
df_before_split <- df_tsibble_interpolated[df_tsibble_interpolated$Date < split_date, ]
df_after_split <- df_tsibble_interpolated[df_tsibble_interpolated$Date >= split_date, ]

# Calculate the mean of Gynecology benign and malignant for 'Sectie'
mean_data <- df_after_split %>%
  group_by(Date) %>%
  filter(Department %in% c("Ginecologie, Benign", "Ginecologie, Malign")) %>%
  summarize(Zile = mean(Zile, na.rm = TRUE))
mean_data$Date <- as.Date(mean_data$Date, format="%Y-%m-%d")
mean_data <- mean_data %>% mutate(Department = "Ginecologie")
# Assuming df_tsibble_interpolated is your main data frame
# Assuming mean_data is the data frame with Date and Zile values

# Filter data for Ginecologie
ginecologie_data <- df_tsibble_interpolated[df_tsibble_interpolated$Department == "Ginecologie", ]
ginecologie_data$Date <- as.Date(ginecologie_data$Date, format="%Y-%m-%d")

# Merge the ginecologie_data with mean_data based on Date
ginecologie_data <- rbind(ginecologie_data, mean_data)

# Round Zile
ginecologie_data$Zile <- round(ginecologie_data$Zile, 0)
ginecologie_data <- filter(ginecologie_data, Date >= "2023-12-15")

# Replace the values in df_tsibble_interpolated with the modified Ginecologie data
merged_data <- rbind(df_tsibble_interpolated, ginecologie_data)
#remove benign and malignant ginecologie
merged_data <- merged_data %>% filter(Department != "Ginecologie, Benign", Department != "Ginecologie, Malign")

merged_data %>% arrange(Department, Date)

df_tsibble_interpolated <- merged_data

# #rename departments
df_tsibble_interpolated_renamed <-  as.data.frame(df_tsibble_interpolated)  %>%
 mutate(Department = case_when(
        Department == "Ginecologie" ~ "Gynecology",
        Department == "Tumori ale pielii, melanom și ALM" ~ "Dermato-Oncology",
        Department == "Broncoscopie Chirurugie de o zi"   ~ "Bronchoscopy", 
        Department == "Gastrologie" ~ "Gastroenterology",
        Department == "Hematologie 1" ~ "Hematology 1",
        Department == "Hematologie 2" ~ "Hematology 2",
        Department == "Hematologie 4" ~ "Hematology 3",
        Department == "Hematologie pentru copii" ~ "Pediatric Hematology",
        Department == "Mamologie, Benign" ~ "Breast Oncosurgery, benign",
        Department == "Mamologie, Malign Primar" ~ "Breast Oncosurgery, primary malignant",
        Department == "Mamologie, Malign Secundar" ~ "Breast Oncosurgery, secondary malignant",
        Department == "Oncologie medicală 1" ~ "Medical Oncology 1",
        Department == "Oncologie medicală 2" ~ "Medical Oncology 2",
        Department == "Oncologie medicală 3" ~ "Medical Oncology 3",
        Department == "Oncologie radiologică 1" ~ "Radiation Oncology 1",
        Department == "Oncologie radiologică 2" ~ "Radiation Oncology 2",
        Department == "Oncologie radiologică 3" ~ "Radiation Oncology 3",
        Department == "Oncologie radiologică 4/Branhiterapia" ~ "Brachytherapy",
        Department == "Pediatrie oncologică" ~ "Pediatric Oncology",
        Department == "Proctologie" ~ "Proctology",
        Department == "Staționar de zi" ~ "Day hospital",
        Department == "Urologie" ~ "Urology",
        Department == "Toraco-abdominală" ~ "Thoracoabdominal oncology",
        Department == "Tumori cap și gât, Anestezie generală" ~ "Head and Neck Tumours, general anaesthesia",
        Department == "Tumori cap și gât, Anestezie locală" ~ "Head and Neck Tumours, local anaesthesia",
        Department == "Tumori cap și gât, Neonco" ~ "Head and Neck Tumours, benign",
        ))
df_tsibble_interpolated <- as_tsibble(df_tsibble_interpolated_renamed, index = Date, key = Department)
# Remove 3 outlier specific rows corresponding to the section and dates
section_to_remove <- "Dermato-Oncology"
dates_to_remove <- as.Date(c("2022-09-09", "2022-09-16", "2022-09-23"))


df_tsibble_interpolated_outlier2 <- df_tsibble_interpolated  %>%
  filter(!(Department == section_to_remove & Date %in% dates_to_remove))


# Generate the missing combinations of Sectie and Date
df_missing_dates <- df_tsibble_interpolated_outlier2 %>%
  complete(Department, Date = seq(min(df_tsibble_interpolated_outlier2$Date),
                               max(df_tsibble_interpolated_outlier2$Date),
                               by = "1 week"))

# Fill in missing values

df_filled <- df_missing_dates %>%
  group_by(Department) %>%
  mutate(Zile = zoo::na.approx(Zile, na.rm = FALSE)) %>%
  ungroup()

df_filled2 <- df_filled %>% mutate(Zile = round(Zile, 0))

df_tsibble_interpolated <- as_tsibble(df_filled2,  index = Date, key = Department)
df_tsibble_interpolated$Zile <- abs(df_tsibble_interpolated$Zile)


#remove outlier sections/ , starts with tumori cap si gat

df_tsibble_interpolated_outlier <- df_tsibble_interpolated %>% 
  filter(!grepl("^Head and", Department))


 
df_tsibble_final <- as_tsibble(df_tsibble_interpolated_outlier,  index = Date, key = Department)


#calculate overall weekly

mean_weekly<-period.apply(df_tsibble_final, INDEX = endpoints(df_tsibble_final, on = "weeks"), FUN = mean)

### or like this
# aggregated <- df_tsibble_final |>
#     aggregate_key(Sectie, Zile = mean(Zile))
#remove sectie empty  column

mean_weekly<- select(mean_weekly, -Department)

#create data frame mean_weekly
mean_weekly_df <- as.data.frame(mean_weekly)
#create date column
mean_weekly_df <- mean_weekly_df %>%
  mutate(Date = rownames(mean_weekly_df), ID = 1:nrow(mean_weekly_df))
rownames(mean_weekly_df) <- NULL
#Mutate date column to date
mean_weekly_df <- mean_weekly_df %>%
mutate(Date = as.Date(Date))

#create tsibble
mean_weekly_df2 <- mean_weekly_df %>% select(-ID) #KEEP IF NEEDED FOR SOMETHING ELSE
mean_weekly_xts <- as.xts(mean_weekly_df2)
mean_weekly_tsibble <- as_tsibble(mean_weekly_df2, index = Date)




#create time series objects 
# 52 weeks in a year. So, start at 2022, week 9
mean_weekly_ts <- ts(mean_weekly_xts, frequency = 52, start = c(2022, 9))
df_ts_interpolated <- ts(df_tsibble_interpolated, frequency = 52, start = c(2022, 9))
df_ts_final <- ts(df_tsibble_final, frequency = 52, start = c(2022, 9))


```
### Exploratory analysis
```{r 3, echo=FALSE}

### mean summary (no outlier section)
summary_mean <- summary(mean_weekly_tsibble)

### summary by sectie (all, with fixed aml)
summary_all <- as.data.frame(df_tsibble_interpolated) %>% 
  select(-Date) %>%
  group_by(Department) %>% 
  summarise(
    mean = round(mean(Zile, na.rm = TRUE), 2), 
    sd = round(sd(Zile, na.rm = TRUE), 2), 
    q1 = quantile(Zile, probs = 0.25, na.rm = TRUE),
    median = median(Zile, na.rm = TRUE), 
    q3 = quantile(Zile, probs = 0.75, na.rm = TRUE),
        iqr = IQR(Zile, na.rm = TRUE),  # Add this line for IQR calculation
    min = min(Zile, na.rm = TRUE), 
    max = max(Zile, na.rm = TRUE), 
    n = n(), 
    n_missing = sum(is.na(Zile)),
    ci_lower = round(mean - qt(0.975, df = n - 1) * (sd / sqrt(n)), 2),
    ci_upper = round(mean + qt(0.975, df = n - 1) * (sd / sqrt(n)), 2)
  ) %>% 
  arrange(mean)


#### Visualise all departments (monthly for clarity)
#
# calculate mean for each month for each sectie using lists 
# #split_data by sectie - list
df_tsibble_interpolated_xts <- as.xts(df_tsibble_interpolated)
split_data <- split(df_tsibble_interpolated_xts, df_tsibble_interpolated_xts$Department)
#calculate mean for each sectie for each month - list
monthly_means <- lapply(split_data, function(x) period.apply(x$Zile, INDEX = endpoints(x, on = "months"), FUN = mean))
#transfomr into df
monthly_means_df <- as.data.frame(monthly_means)
monthly_means_df <- monthly_means_df %>%
  mutate(Date = row.names(monthly_means_df)) %>%
  mutate(Date = as.Date(Date, format = "%Y-%m-%d"))
#pivot longer
monthly_means_df <- pivot_longer(monthly_means_df, cols = -Date, names_to = "Department", values_to = "Zile")
monthly_means_df <- monthly_means_df %>%
  mutate(Zile = round(Zile, 1))
##graph
graph_ggplot_all<- monthly_means_df %>% 
  ggplot(aes(x = Date, y = Zile, color = Department)) +
   geom_line(aes(group = Department), linetype=1, linewidth=.2) +
  geom_point(size = 0.7) +
  theme_tq() +
  scale_y_continuous(labels = scales::number_format(scale = 1, accuracy = 1)) +
  scale_x_date(date_breaks = "3 months")+
  labs(title = 'Weekly hospital admission delay',
           x = "",
           y = 'Nr. of days')  

graph_all <- ggplotly(graph_ggplot_all)

###outliers determined (3 deps, exclude further)

##### Check for correlations between departments

wide_df <- spread(df_tsibble_final, key = Department, value = Zile)

# Extract numeric columns from wide_df (excluding the Date column)
numeric_columns <- wide_df[, sapply(wide_df, is.numeric)]
numeric_columns <- numeric_columns[,-16]

 



corr <- round(cor(numeric_columns), 1)
p.mat <- cor_pmat(numeric_columns)
p.mat_longer <- melt(p.mat)
p.mat_longer <- p.mat_longer %>% mutate(p_adj=p.adjust(value, method='BH'))
p.mat_longer <- p.mat_longer %>% select(-value)
#back to wide
p.mat_wide <- spread(p.mat_longer, key = Var2, value = p_adj)
#var1 to rownames
rownames(p.mat_wide) <- p.mat_wide$Var1
p.mat_wide <- p.mat_wide %>% select(-Var1) # ADJUSTED P-vals
hmap<-ggcorrplot(
  corr,
  p.mat = p.mat_wide,
  hc.order = TRUE,
  type = "lower",
  insig = "blank",
  lab = TRUE,
)
##### Visualize mean

#Rolling mean

  smoothed_data <- zoo::rollmean(mean_weekly_tsibble$Zile, k = 5, fill = NA)
  ma_weekly <- mean_weekly_tsibble %>%
    mutate(`5-MA` = smoothed_data)
ma_weekly <- as_tsibble(ma_weekly, index = Date)
ma_weekly2 <- ma_weekly %>%
  select(-Zile)

ma_weekly2 <- as_tsibble(ma_weekly2, index = Date)


### Graph the data with MA
graph_ggplot1<- ma_weekly %>% 
  ggplot(aes(x = Date, y = Zile)) + 
  geom_line(colour = 'darkblue') +
   geom_line(aes(y = `5-MA`), colour = "darkred", linetype = 2, linewidth = 1)+
  theme_tq() +
  scale_y_continuous(labels = scales::number_format(scale = 1, accuracy = 1)) +
  scale_x_date(date_breaks = "3 months")+
  labs(title = 'Weekly hospital admission delay',
           x = "",
           y = 'Nr. of days')  
graph_mean_weekly <- ggplotly(graph_ggplot1)
#also this
graph_ggplot2 <- plot_time_series(mean_weekly_tsibble, Date, Zile)

### show trend by fitting a linear model
linear_model_weekly<- mean_weekly_tsibble %>%
model (linear = TSLM(Zile ~ trend()))

linear_model_weekly_rep <- report(linear_model_weekly) # p val significant for trend

trend_plot <- ggplotly(
  graph_ggplot1 +
  autolayer(fitted(linear_model_weekly_rep), colour ="red") 
)

 

#ggplot object with gg_season
graph_seasonal <- #ggplotly(
  gg_season(mean_weekly_tsibble,  pal = c('darkblue', 'darkred'), linewidth = 0.9) + geom_point() +
    theme_tq() +   scale_y_continuous(limits = c(5, 20), labels = scales::number_format(scale = 1, accuracy = 1))+
    labs(title = 'Delay dynamics by year', x = "", y = 'Nr. of days') + scale_x_date(date_breaks = "1 month", date_labels = "%m")
 # )

#same graph but for rolling mean
graph_seasonal_rolling_mean <- #ggplotly(
  gg_season(ma_weekly2,  pal = c('darkblue', 'darkred'), linewidth = 0.9) +
    theme_tq() + geom_point() + scale_y_continuous(limits = c(9, 16), labels = scales::number_format(scale = 1, accuracy = 1)) +
    labs(title = 'Delay dynamics by year', x = "", y = 'Rolling mean') + scale_x_date(date_breaks = "1 month", date_labels = "%m")
  #)
 

###acf plot, acf drops quickly, not sure how useful, in non-stationary data it drops slowly
graph_acf <- ts_cor(mean_weekly_ts_1year, lag.max = 52)
graph_acf2 <- ts_cor(mean_weekly_ts, lag.max = 52, seasonal = FALSE)

### STL decomposition

#decompose - does not seem to be seasons
stl_decomp<- df_tsibble_final |>
group_by(Department) %>%
    model(
    STL(Zile ~ trend(window = 7) +
                   season(window = "periodic"),
    robust = TRUE)) |>
  components() 

#stl features
stl_features <- features(df_tsibble_final, Zile, feat_stl)

trend_strength <- ggplot(stl_features, aes(x = Department, y =trend_strength)) +
  geom_col() +
  coord_flip() +
  labs(title = "Trend strength for each section")
```
### Exploratory for Gynecology
```{r} 
### for the purpose of this paper ginecologie will be used as an example because of high variance and unpredictability
dfdf2 <- as.data.frame(subset(df_tsibble_final, Department == "Gynecology")) %>%
  select(-Department)
dfdf2_tsibble <- as_tsibble(dfdf2, index = Date)
dfdf2_xts <- as.xts(dfdf2_tsibble, index = Date)
dfdf2_ts <- ts(dfdf2_xts, frequency = 52, start = c(2022, 9))

unitroot_kpss(dfdf2_tsibble$Zile)
hurst_features <- coef_hurst(dfdf2_tsibble$Zile)
### graph gineco

graph_gineco <- plot_time_series(dfdf2_tsibble, Date, Zile)

graph_ginecologie <- dfdf2 %>% 
  ggplot(aes(x = Date, y = Zile)) + 
  geom_line(colour = 'darkblue') +
  geom_smooth( se = FALSE, colour = "darkred", linetype = 2, span = 0.2)+
  theme_tq() +
  scale_y_continuous(labels = scales::number_format(scale = 1, accuracy = 1)) +
  scale_x_date(date_breaks = "3 months")+
  labs(title = '',
           x = "",
           y = 'Nr. of days')  +   theme(axis.text.x = element_text(angle = 30, hjust = 1))
graph_ginecologie_plotly <- ggplotly(graph_ginecologie)

graph_mean_weekly <- ggplotly(graph_ggplot1)


#Rolling mean gineco

  smoothed_data_gin <- zoo::rollmean(dfdf2_tsibble$Zile, k = 3, fill = NA, align = "right")
  ma_weekly_gin <- dfdf2_tsibble %>%
    mutate(MA = smoothed_data_gin)
ma_weekly_gin <- as_tsibble(ma_weekly_gin, index = Date)
ma_weekly_gin2 <- ma_weekly_gin %>%
  select(-Zile)

ma_weekly_gin2 <- as_tsibble(ma_weekly_gin2, index = Date)

### seasonality gineco

graph_seasonal_gineco <- ts_seasonal(dfdf2_tsibble, type = "normal", title = "", palette_normal = "Spectral", Xgrid = FALSE, Ygrid = FALSE)
graph_seasonal_gineco_ma <- ts_seasonal(ma_weekly_gin2, type = "normal", title = "", palette_normal = "Spectral", Xgrid = FALSE, Ygrid = FALSE)

### acf gineco
graph_acf_gineco <- ts_cor(dfdf2_ts, lag.max = 52, seasonal = FALSE)

### STL decomposition

#decompose - does not seem to be seasons
stl_decomp_gineco<- dfdf2_tsibble |>
    model(
    STL(Zile ~ trend(window = 7) +
                   season(window = "periodic"),
    robust = TRUE)) |>
  components() 

#stl features
stl_features_gineco <- features(dfdf2_tsibble, Zile, feat_stl)


### show trend by fitting a linear model
linear_model_gineco<- dfdf2_tsibble %>%
model (linear = TSLM(Zile ~ trend()))

linear_model_gineco_rep <- report(linear_model_gineco) # p val significant for trend

tslaggs <-  ts_lags(dfdf2_ts, lags = c(1, 2, 3, 26, 39, 52)) #linear correlation between series and lag for 1 and 2 but not for 13, 26, 39, 52 (+1 week to 4 for every 3 mnths)
acf_features <- features(dfdf2_tsibble, Zile, feat_acf, )
acf_gin <- ACF(dfdf2_tsibble, Zile, lag_max = 52)

##### Stationarity and differencing
###check for stationarity
stationary <- df_tsibble_final |>
     group_by(Department) %>%
     features(Zile, unitroot_kpss)

### some departments are not stationary, so we will use the diff() function to make them stationary
stationary_diff_gineco <- dfdf2_tsibble |>
    mutate(diff = difference(Zile)) %>%
    features(diff, unitroot_kpss) 
      #Now stationary

##### Visualise diff 
#calculate diff
df_diff_all <- df_tsibble_final |>
    group_by(Department) %>%
    mutate(diff = difference(Zile))
## calculate mean for each month for each sectie using lists
# split_data by sectie - list
df_diff_all_xts <- as.xts(df_diff_all)
split_data_diff <- split(df_diff_all_xts, df_diff_all_xts$Department)
#calculate mean for each sectie for each month - list
monthly_means_diff <- lapply(split_data_diff, function(x) period.apply(x$diff, INDEX = endpoints(x, on = "months"), FUN = mean))
#transfomr into df
monthly_means_df_diff <- as.data.frame(monthly_means_diff)
monthly_means_df_diff <- monthly_means_df_diff %>%
  mutate(Date = row.names(monthly_means_df_diff)) %>%
  mutate(Date = as.Date(Date, format = "%Y-%m-%d"))
#pivot longer
monthly_means_df_diff <- pivot_longer(monthly_means_df_diff, cols = -Date, names_to = "Department", values_to = "Difference")
monthly_means_df_diff <- monthly_means_df_diff %>%
  mutate(Difference = round(Difference, 1))

df_diff <- df_diff_all %>%
  subset(Department == "Gynecology") %>%
  select(Date, diff)
df_diff <- as.data.frame(df_diff) %>%
  select(-Department)
df_diff <- as_tsibble(df_diff, index = Date)
### graph
dfdf2_diff <- dfdf2_tsibble |>
    mutate(Difference = difference(Zile))
graph_ggplot_diff_gineco<- dfdf2_diff %>%
  ggplot(aes(x = Date, y = Difference)) +
  geom_line() +
  geom_point(size = 0.7) +
  theme_tq() +
  scale_y_continuous(labels = scales::number_format(scale = 1, accuracy = 1)) +
  scale_x_date(date_breaks = "3 months")+
  labs(title = 'Differenced data',
           x = "",
           y = 'Difference')

graph_gineco_diff <- ggplotly(graph_ggplot_diff_gineco)
####

 


```
### ML models, method one

```{r}
 

###Feature creation and preprocessing
#no trend apparently if you include rollmean . k= 3 yields the highest rsq value when compared to k = 5, 7, 9, 11, 13

# Fit the linear model
linear_model_gineco_ML <- dfdf2_tsibble %>%
  model(linear = TSLM(Zile ~ trend()))

# Extract the linear trend component
linear_trend <- as.data.frame(fitted(linear_model_gineco_ML)) %>%
  select(.fitted)

linear_trend <- as.numeric(linear_trend$.fitted)

#exp mean
Expanding_means <- rollapply(dfdf2_ts, width = seq_along(dfdf2_ts), FUN = mean, align = "right")
Expanding_means <- as.numeric(Expanding_means)

#### Sample holidays (excluding the year) - Check if holiday was within a week
holidays <- c("01-01", "07-01", "08-03", "04-09", "05-01", "09-05", "27-08", "31-08", "06-10", "25-12")
# Set a time window (e.g., within a week)
time_window <- 7
# Function to calculate binary indicator for adjacent holidays
is_adjacent_holiday <- function(data_date) {
  adjacent <- any(abs(as.Date(holidays, format = "%d-%m") - as.Date(data_date)) <= time_window)
  return(as.numeric(adjacent))
}

# Create binary indicator variable
adj_holid <- dfdf2 %>%
  mutate(adjacent_holiday = sapply(Date, is_adjacent_holiday))
adj_holid <- adj_holid %>%
  select(adjacent_holiday)
adj_holid <- as.numeric(adj_holid$adjacent_holiday)




#not enough data to capture long term trends I think
model_data_tbl <- dfdf2_tsibble %>% 
  mutate( Linear_trend = linear_trend,
          # Rolling_mean_2 = rollmean(Zile, k = 2, fill = NA, align = "right"),
          # Rolling_mean_5 = rollmean(Zile, k = 5, fill = NA, align = "right"),
           Rolling_mean_7 = rollmean(Zile, k = 7, fill = NA, align = "right"),
          Rolling_mean_9 = rollmean(Zile, k = 9, fill = NA, align = "right"),
          Rolling_mean_13 = rollmean(Zile, k = 13, fill = NA, align = "right"),
          # Rolling_mean_26 = rollmean(Zile, k = 26, fill = NA, align = "right"),
          # SD_2 = rollapply(Zile, width = 2, FUN = sd, fill = NA, align = "right"),
          # SD_5 = rollapply(Zile, width = 5, FUN = sd, fill = NA, align = "right"),
           SD_7 = rollapply(Zile, width = 7, FUN = sd, fill = NA, align = "right"),
          SD_9 = rollapply(Zile, width = 9, FUN = sd, fill = NA, align = "right"),
          SD_13 = rollapply(Zile, width = 13, FUN = sd, fill = NA, align = "right"),
          # SD_26 = rollapply(Zile, width = 26, FUN = sd, fill = NA, align = "right"),
          Expanding_mean = Expanding_means,
          Rev_lag_1   = lag(Zile, n = 1),
          Rev_lag_2   = lag(Zile, n = 2),
          Rev_lag_3   = lag(Zile, n = 3),
          Rev_lag_4  = lag(Zile, n = 4),
          Rev_lag_5   = lag(Zile, n = 5),
          Rev_lag_6   = lag(Zile, n = 6),
          Rev_lag_7   = lag(Zile, n = 7),
    # Rolling_mean_2_Lag_1 = Rolling_mean_2 * Rev_lag_1,
    # Rolling_mean_2_Lag_2 = Rolling_mean_2 * Rev_lag_2,
    # Rolling_mean_13_Lag_1 = Rolling_mean_13 * Rev_lag_1,
    # Rolling_mean_13_Lag_2 = Rolling_mean_13 * Rev_lag_2,
    # Rolling_mean_26_Lag_1 = Rolling_mean_26 * Rev_lag_1,
    # Rolling_mean_26_Lag_2 = Rolling_mean_26 * Rev_lag_2,
    # EMA_2 = EMA(Zile, n = 2),
    # EMA_5 = EMA(Zile, n = 5),
     EMA_7 = EMA(Zile, n = 7),
    EMA_9 = EMA(Zile, n = 9),
    EMA_13 = EMA(Zile, n = 13),
    # DEMA_2 = DEMA(Zile, n = 2),
    # DEMA_5 = DEMA(Zile, n = 5),
     DEMA_7 = DEMA(Zile, n = 7),
    DEMA_9 = DEMA(Zile, n = 9),
    DEMA_13 = DEMA(Zile, n = 13),
    # DEMA_26 = DEMA(Zile, n = 26),
    # WMA_2 = WMA(Zile, n = 2),
    # WMA_5 = WMA(Zile, n = 5),
     WMA_7 = WMA(Zile, n = 7),
    WMA_9 = WMA(Zile, n = 9),
    WMA_13 = WMA(Zile, n = 13),
    # EMA_2_Lag_1 = EMA_2 * Rev_lag_1,
    # EMA_2_Lag_2 = EMA_2 * Rev_lag_2,
    # EMA_13_Lag_1 = EMA_13 * Rev_lag_1,
    # EMA_13_Lag_2 = EMA_13 * Rev_lag_2,
    # EMA_5_Lag_1 = EMA_5 * Rev_lag_1,
    # EMA_5_Lag_2 = EMA_5 * Rev_lag_2,
    # EMA_7_Lag_1 = EMA_7 * Rev_lag_1,
    # EMA_7_Lag_2 = EMA_7 * Rev_lag_2,
    # EMA_9_Lag_1 = EMA_9 * Rev_lag_1,
    # EMA_9_Lag_2 = EMA_9 * Rev_lag_2,
    #       month_january = as.numeric(lubridate::month(Date) == 1),
    # month_february = as.numeric(lubridate::month(Date) == 2),
    # month_march = as.numeric(lubridate::month(Date) == 3),
    # month_april = as.numeric(lubridate::month(Date) == 4),
    # month_may = as.numeric(lubridate::month(Date) == 5),
    # month_june = as.numeric(lubridate::month(Date) == 6),
    # month_july = as.numeric(lubridate::month(Date) == 7),
    # month_august = as.numeric(lubridate::month(Date) == 8),
    # month_september = as.numeric(lubridate::month(Date) == 9),
    # month_october = as.numeric(lubridate::month(Date) == 10),
    # month_november = as.numeric(lubridate::month(Date) == 11),
    # month_december = as.numeric(lubridate::month(Date) == 12),
    Month = lubridate::month(Date),
    Quarter = lubridate::quarter(Date),
     Year = lubridate::year(Date),
    Week_of_Year = isoweek(Date),
    Day_of_year = yday(Date),
    Outlier_indicator = as.numeric(Zile < quantile(Zile, 0.05) | Zile > quantile(Zile, 0.95)),
     Adjacent_holiday = adj_holid
        ) %>% filter(!is.na(Rev_lag_1) & !is.na(Rev_lag_7)  & !is.na(SD_13)
           # !is.na(Rolling_mean_2) & !is.na(Rolling_mean_13)  & 
           )

 
```


###train 1
```{r}
#Split into train test and FC

train_tbl_ML2 <- model_data_tbl %>% filter(Date < ymd("2022-12-02"))
test_tbl_ML2  <- model_data_tbl %>% filter(Date >= ymd("2022-12-02") & Date <= ymd("2023-01-20"))


### Modelling
  
  #initiate h2o
  h2o.init(max_mem_size = "16G")
h2o.no_progress()

# response variable
y <- "Zile"

# predictors set: remove response variable and date from the set
x <- setdiff(names(train_tbl_ML2 %>% as.h2o()), c(y, "Date"))

### Random Forrest
rft_model22 <- 
  h2o.automl(
    x = x,
    y = y,
    training_frame = train_tbl_ML2 %>% as.h2o(),
    nfolds = 0,
    validation_frame = test_tbl_ML2 %>% as.h2o(),
    include_algos = c("DRF"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
  rft_model2 <- rft_model22@leader
 

# gradient boosting machine model
gbm_model22 <-  
 h2o.automl(
    x = x,
    y = y,
    training_frame = train_tbl_ML2 %>% as.h2o(),
    nfolds = 0,
    validation_frame = test_tbl_ML2 %>% as.h2o(),
    include_algos = c("GBM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 gbm_model2 <- gbm_model22@leader
 

# generalised linear model 
glm_model22 <- 
 h2o.automl(
    x = x,
    y = y,
    training_frame = train_tbl_ML2 %>% as.h2o(),
    nfolds = 0,
    validation_frame = test_tbl_ML2 %>% as.h2o(),
    include_algos = c("GLM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
  glm_model2 <- glm_model22@leader

#Deep learning
automl_model2 <-
  h2o.automl(
    x = x,
    y = y,
    training_frame = train_tbl_ML2 %>% as.h2o(),
    nfolds = 0,
    validation_frame = test_tbl_ML2 %>% as.h2o(),
    include_algos = c("DeepLearning"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
    # see best auto model
      automl_model2@leaderboard
      
### Extract and save the leader autoML model
  aml_model2 <- automl_model2@leader
  
    #performances
perf_rft2 <- h2o.performance(rft_model2, newdata = as.h2o(test_tbl_ML2))
perf_gbm2 <- h2o.performance(gbm_model2, newdata = as.h2o(test_tbl_ML2))
perf_glm2 <- h2o.performance(glm_model2, newdata = as.h2o(test_tbl_ML2))
perf_aml2 <- h2o.performance(aml_model2, newdata = as.h2o(test_tbl_ML2))

metrics_table2 <- tibble(
  Model = c("Random Forest 1", "GBM 1", "GLM 1", "DL 1"),
  R_squared = c(
    h2o.r2(perf_rft2),
    h2o.r2(perf_gbm2),
    h2o.r2(perf_glm2),
    h2o.r2(perf_aml2)
  ),
  MAE = c(
    h2o.mae(perf_rft2),
    h2o.mae(perf_gbm2),
    h2o.mae(perf_glm2),
    h2o.mae(perf_aml2)
  ),
  RMSE = c(
    h2o.rmse(perf_rft2),
    h2o.rmse(perf_gbm2),
    h2o.rmse(perf_glm2),
    h2o.rmse(perf_aml2)
  )
) %>% arrange(desc(R_squared))
```
### train 2
```{r}
#Split into train test and FC

train_tbl_ML3 <- model_data_tbl %>% filter(Date < ymd("2023-01-27"))
  test_tbl_ML3  <- model_data_tbl %>% filter(Date >= ymd("2023-01-27") & Date <= ymd("2023-03-17"))
  
  
  ### Modelling

# response variable
y <- "Zile"

# predictors set: remove response variable and date from the set
x <- setdiff(names(train_tbl_ML3 %>% as.h2o()), c(y, "Date"))

### Random Forrest
rft_model33 <- 
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML3),
    nfolds             = 0,
     validation_frame   = test_tbl_ML3 %>% as.h2o(),
        include_algos = c("DRF"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 rft_model3 <- rft_model33@leader
# gradient boosting machine model
gbm_model33 <-  
 h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML3),
    nfolds             = 0,
     validation_frame   = test_tbl_ML3 %>% as.h2o(),
        include_algos = c("GBM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
  gbm_model3 <- gbm_model33@leader


# generalised linear model 
glm_model33 <- 
 h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML3),
    nfolds             = 0,
     validation_frame   = test_tbl_ML3 %>% as.h2o(),
        include_algos = c("GLM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 glm_model3 <- glm_model33@leader

#automl funciton
automl_model3 <-
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML3),
    nfolds             = 0,
     validation_frame   = test_tbl_ML3 %>% as.h2o(),
        include_algos = c("DeepLearning"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 
      
### Extract and save the leader autoML model
  aml_model3 <- automl_model3@leader
  
    #performances
perf_rft3 <- h2o.performance(rft_model3, newdata = test_tbl_ML3 %>% as.h2o())
perf_gbm3 <- h2o.performance(gbm_model3, newdata = as.h2o(test_tbl_ML3))
perf_glm3 <- h2o.performance(glm_model3, newdata = as.h2o(test_tbl_ML3))
perf_aml3 <- h2o.performance(aml_model3, newdata = as.h2o(test_tbl_ML3))

metrics_table3 <- tibble(
  Model = c("Random Forest 2", "GBM 2", "GLM 2", "DL 2"),
  R_squared = c(
    h2o.r2(perf_rft3),
    h2o.r2(perf_gbm3),
    h2o.r2(perf_glm3),
    h2o.r2(perf_aml3)
  ),
  MAE = c(
    h2o.mae(perf_rft3),
    h2o.mae(perf_gbm3),
    h2o.mae(perf_glm3),
    h2o.mae(perf_aml3)
  ),
  RMSE = c(
    h2o.rmse(perf_rft3),
    h2o.rmse(perf_gbm3),
    h2o.rmse(perf_glm3),
    h2o.rmse(perf_aml3)
  )
) %>% arrange(desc(R_squared))

```
### train 3
```{r}
#Split into train test and FC

train_tbl_ML4 <- model_data_tbl %>% filter(Date < ymd("2023-03-24"))
  test_tbl_ML4  <- model_data_tbl %>% filter(Date >= ymd("2023-03-24") & Date <= ymd("2023-05-12"))
  
  
  ### Modelling

# response variable
y <- "Zile"

# predictors set: remove response variable and date from the set
x <- setdiff(names(train_tbl_ML4 %>% as.h2o()), c(y, "Date"))

### Random Forrest
rft_model44 <- 
 h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML4),
    nfolds             = 0,
     validation_frame   = test_tbl_ML4 %>% as.h2o(),
            include_algos = c("DRF"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 rft_model4<- rft_model44@leader

# gradient boosting machine model
gbm_model44 <-  
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML4),
    nfolds             = 0,
     validation_frame   = test_tbl_ML4 %>% as.h2o(),
            include_algos = c("GBM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
gbm_model4 <- gbm_model44@leader
# generalised linear model 
glm_model44 <- 
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML4),
    nfolds             = 0,
     validation_frame   = test_tbl_ML4 %>% as.h2o(),
            include_algos = c("GLM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
glm_model4 <- glm_model44@leader
#automl funciton
automl_model4 <-
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML4),
    nfolds             = 0,
     validation_frame   = test_tbl_ML4 %>% as.h2o(),
            include_algos = c("DeepLearning"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 
      
### Extract and save the leader autoML model
  aml_model4 <- automl_model4@leader
  
    #performances
perf_rft4 <- h2o.performance(rft_model4, newdata = test_tbl_ML4 %>% as.h2o())
perf_gbm4 <- h2o.performance(gbm_model4, newdata = as.h2o(test_tbl_ML4))
perf_glm4 <- h2o.performance(glm_model4, newdata = as.h2o(test_tbl_ML4))
perf_aml4 <- h2o.performance(aml_model4, newdata = as.h2o(test_tbl_ML4))

metrics_table4 <- tibble(
  Model = c("Random Forest 3", "GBM 3", "GLM 3", "DL 3"),
  R_squared = c(
    h2o.r2(perf_rft4),
    h2o.r2(perf_gbm4),
    h2o.r2(perf_glm4),
    h2o.r2(perf_aml4)
  ),
  MAE = c(
    h2o.mae(perf_rft4),
    h2o.mae(perf_gbm4),
    h2o.mae(perf_glm4),
    h2o.mae(perf_aml4)
  ),
  RMSE = c(
    h2o.rmse(perf_rft4),
    h2o.rmse(perf_gbm4),
    h2o.rmse(perf_glm4),
    h2o.rmse(perf_aml4)
  )
) %>% arrange(desc(R_squared))
```
### train 4
```{r}
#Split into train test and FC

train_tbl_ML5 <- model_data_tbl %>% filter(Date < ymd("2023-05-19"))
  test_tbl_ML5  <- model_data_tbl %>% filter(Date >= ymd("2023-05-19") & Date <= ymd("2023-07-07"))
  
 

  ### Modelling

# response variable
y <- "Zile"

# predictors set: remove response variable and date from the set
x <- setdiff(names(train_tbl_ML5 %>% as.h2o()), c(y, "Date"))

 


### Random Forrest
rft_model55 <- 
   h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML5),
    nfolds             = 0,
     validation_frame   = test_tbl_ML5 %>% as.h2o(),
                include_algos = c("DRF"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 rft_model5 <- rft_model55@leader

# gradient boosting machine model
gbm_model55 <-  
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML5),
    nfolds             = 0,
     validation_frame   = test_tbl_ML5 %>% as.h2o(),
                include_algos = c("GBM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
gbm_model5 <- gbm_model55@leader
# generalised linear model 
glm_model55 <- 
 h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML5),
    nfolds             = 0,
     validation_frame   = test_tbl_ML5 %>% as.h2o(),
                include_algos = c("GLM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
glm_model5 <- glm_model55@leader
#automl funciton
automl_model5 <-
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML5),
    nfolds             = 0,
     validation_frame   = test_tbl_ML5 %>% as.h2o(),
                include_algos = c("DeepLearning"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 
      
### Extract and save the leader autoML model
  aml_model5 <- automl_model5@leader
  
    #performances
perf_rft5 <- h2o.performance(rft_model5, newdata = test_tbl_ML5 %>% as.h2o())
perf_gbm5 <- h2o.performance(gbm_model5, newdata = as.h2o(test_tbl_ML5))
perf_glm5 <- h2o.performance(glm_model5, newdata = as.h2o(test_tbl_ML5))
perf_aml5 <- h2o.performance(aml_model5, newdata = as.h2o(test_tbl_ML5))

metrics_table5 <- tibble(
  Model = c("Random Forest 4", "GBM 4", "GLM 4", "DL 4"),
  R_squared = c(
    h2o.r2(perf_rft5),
    h2o.r2(perf_gbm5),
    h2o.r2(perf_glm5),
    h2o.r2(perf_aml5)
  ),
  MAE = c(
    h2o.mae(perf_rft5),
    h2o.mae(perf_gbm5),
    h2o.mae(perf_glm5),
    h2o.mae(perf_aml5)
  ),
  RMSE = c(
    h2o.rmse(perf_rft5),
    h2o.rmse(perf_gbm5),
    h2o.rmse(perf_glm5),
    h2o.rmse(perf_aml5)
  )
) %>% arrange(desc(R_squared))
```
## train 5

``` {r}

#Split into train test and FC

train_tbl_ML <- model_data_tbl %>% filter(Date < ymd("2023-07-14"))
  test_tbl_ML  <- model_data_tbl %>% filter(Date >= ymd("2023-07-14") & Date <= ymd("2023-09-01"))
  
  
  

# response variable
y <- "Zile"

# predictors set: remove response variable and date from the set
x <- setdiff(names(train_tbl_ML %>% as.h2o()), c(y, "Date"))

### Random Forrest
rft_model6 <- 
   h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML),
    nfolds             = 0,
     validation_frame   = test_tbl_ML %>% as.h2o(),
                    include_algos = c("DRF"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
rft_model <- rft_model6@leader
# gradient boosting machine model
gbm_model6 <-  
   h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML),
    nfolds             = 0,
     validation_frame   = test_tbl_ML %>% as.h2o(),
                    include_algos = c("GBM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
gbm_model <- gbm_model6@leader
# generalised linear model 
glm_model6 <- 
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML),
    nfolds             = 0,
     validation_frame   = test_tbl_ML %>% as.h2o(),
                    include_algos = c("GLM"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
glm_model <- glm_model6@leader

#automl funciton
automl_model <-
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train_tbl_ML),
    nfolds             = 0,
     validation_frame   = test_tbl_ML %>% as.h2o(),
                    include_algos = c("DeepLearning"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 60,
    sort_metric       = "RMSE",
    seed               = 1975
 )
    # see best auto model
      automl_model@leaderboard
      
### Extract and save the leader autoML model
  aml_model <- automl_model@leader
  #performances
perf_rft <- h2o.performance(rft_model, newdata = test_tbl_ML %>% as.h2o())
perf_gbm <- h2o.performance(gbm_model, newdata = as.h2o(test_tbl_ML))
perf_glm <- h2o.performance(glm_model, newdata = as.h2o(test_tbl_ML))
perf_aml <- h2o.performance(aml_model, newdata = as.h2o(test_tbl_ML))

metrics_table <- tibble(
  Model = c("Random Forest 5", "GBM 5", "GLM 5", "DL 5"),
  R_squared = c(
    h2o.r2(perf_rft),
    h2o.r2(perf_gbm),
    h2o.r2(perf_glm),
    h2o.r2(perf_aml)
  ),
  MAE = c(
    h2o.mae(perf_rft),
    h2o.mae(perf_gbm),
    h2o.mae(perf_glm),
    h2o.mae(perf_aml)
  ),
  RMSE = c(
    h2o.rmse(perf_rft),
    h2o.rmse(perf_gbm),
    h2o.rmse(perf_glm),
    h2o.rmse(perf_aml)
  )
) %>% arrange(desc(R_squared))
```
###  Model performance
```{r}
    ### Model performance

  #rft_model@model$model_summary

#combine metrics tables
metrics_table_final <- rbind(metrics_table5, metrics_table2, metrics_table3, metrics_table4, metrics_table)

metrics_table_final$Model <- gsub("\\d", "", metrics_table_final$Model)

#calculate mean of metrics for each model
metrics_table_mean <- metrics_table_final %>% group_by(Model) %>% summarise_all(mean)
```
###  Forecast on the Validation data set 
```{r}
# NAMES TEST and VALIDATION ARE SWAPPED HERE
test <- model_data_tbl %>% filter(Date >= ymd("2023-09-08") & Date <= ymd("2023-10-27"))
validation <- model_data_tbl %>% filter(Date > ymd("2023-10-27"))
train <- model_data_tbl %>% filter(Date < ymd("2023-09-08"))


# response variable
y <- "Zile"

# predictors set: remove response variable and date from the set
x <- setdiff(names(train %>% as.h2o()), c(y, "Date"))
#use only the two best models 
DL_test <-
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train),
    nfolds             = 0,
     validation_frame   = test %>% as.h2o(),
                    include_algos = c("DeepLearning"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 120,
    sort_metric       = "RMSE",
    seed               = 1975
 )
 
DL_model_test <- DL_test@leader
perf_dl_test <- h2o.performance(DL_model_test, newdata = as.h2o(test))
# gbm_model_test <- gbm_test@leader
# perf_gbm_test <- h2o.performance(gbm_model_test, newdata = as.h2o(test))


metrics_test <- tibble(
  Model = c( "DL "),
  R_squared = c(
    # h2o.r2(perf_gbm_test),
    h2o.r2(perf_dl_test)
  ),
  MAE = c(
  # h2o.mae(perf_gbm_test),
    h2o.mae(perf_dl_test)
  ),
  RMSE = c(
   # h2o.rmse(perf_gbm_test),
    h2o.rmse(perf_dl_test)
  )
) %>% arrange(desc(R_squared))
```

###  Forecast on the TEST,  Actual vs predicted

```{r}

perf_dl_validation <- h2o.performance(DL_model_test, newdata = as.h2o(validation))
metrics_validation <- tibble(
  Model = c(  "DL "),
  R_squared = c(
    
    h2o.r2(perf_dl_validation)
  ),
  MAE = c(
 
    h2o.mae(perf_dl_validation)
  ),
  RMSE = c(
  
    h2o.rmse(perf_dl_validation)
  )
) %>% arrange(desc(R_squared))
### Actual vs Predicted


predictions_dl <- as.vector(h2o.predict(DL_model_test, as.h2o(validation))$predict)


 actual_values_test <- as.data.frame(validation) %>%
  select(Date, Zile)
actual_vs_predicted_test <- cbind(actual_values_test,  DL = predictions_dl) %>% dplyr::rename(Actual = Zile)

plot_final <-actual_vs_predicted_test %>%
 plot_ly() %>% 
    add_lines(x = ~ Date, y = ~ Actual, name = 'Actual values', line = list(color = 'darkblue')) %>% 
    
    add_lines(x = ~ Date, y = ~ DL, name = 'Deep Learning', 
              line = list(dash = 'dot', color = 'red')) %>% 
     layout(
    title = list(text = '', font = list(size = 16, color = 'black')),
    yaxis = list(title = list(text = 'Nr. of days', font = list(size = 14, color = 'black'))),
    xaxis = list(title = list(text = ''), font = list(size = 14)),
    legend = list(orientation = 'h', font = list(size = 12))
  )

```

### VIP and AvP plots (first test), best model
```{r}
  #aml_model %>% h2o.varimp_plot()

  ###Variable importance plots
# p_glm <- vip(glm_model2) + ggtitle("GLM")
# p_rft <- vip(rft_model2) + ggtitle("RF")
# p_gbm <- vip(gbm_model_test) + ggtitle("GBM")
p_aml <- vip(DL_model_test) + ggtitle("DL")

vi_plot <- grid.arrange(p_gbm, p_aml, nrow = 2)

  #### AVP
# predictions_gbm <- as.vector(h2o.predict(gbm_model_test, as.h2o(test))$predict)
predictions_aml <- as.vector(h2o.predict(DL_model_test, as.h2o(test))$predict)
# predictions_rft <- as.vector(h2o.predict(rft_model2, as.h2o(test))$predict)
# predictions_glm <- as.vector(h2o.predict(glm_model2, as.h2o(test))$predict)

 actual_values_validation <- as.data.frame(test) %>%
  select(Date, Zile)
actual_vs_predicted_validation <- cbind(actual_values_validation,    DL = predictions_aml) %>% dplyr::rename(Actual = Zile)


### Plot a vs p TEST
plot_avp <-actual_vs_predicted_validation %>%
 plot_ly() %>% 
    add_lines(x = ~ Date, y = ~ Actual, name = 'Actual values', line = list(color = 'darkblue')) %>% 
     # add_lines(x = ~ Date, y = ~ RFT, name = 'Random Forest', 
     #           line = list(dash = 'dot', color = 'orange')) %>% 
    # add_lines(x = ~ Date, y = ~ GBM, name = 'Gradient Boosting', 
    #           line = list(dash = 'dash', color = 'green')) %>% 
    add_lines(x = ~ Date, y = ~ DL, name = 'Deep Learning', 
              line = list(dash = 'dot', color = 'red')) %>% 
    #  add_lines(x = ~ Date, y = ~ GLM, name = 'Generalised Linear Model', 
    #            line = list(dash = 'dash', color = 'purple')) %>% 
     layout(
    title = list(text = '', font = list(size = 16, color = 'black')),
    yaxis = list(title = list(text = 'Nr. of days', font = list(size = 14, color = 'black'))),
    xaxis = list(title = list(text = ''), font = list(size = 14)),
    legend = list(orientation = 'h', font = list(size = 12))
  )

### Cross-correlation
Actual <- actual_vs_predicted_test$Actual
Predicted <- actual_vs_predicted_test$DL
actual_vs_predicted_validation_tsibble <- actual_vs_predicted_validation %>%
  as_tsibble(index = Date)
crosscor<- ccf(Actual, Predicted, lag.max = 15, plot = TRUE, ylab = "Cross-correlation", main = "")
crosscor2<- CCF(actual_vs_predicted_validation_tsibble, Actual, DL)
 



```
###Forecast on differenced data
```{r}



#exp mean.
df_diff <- df_diff [-1,]
df_diff_xts <- as.xts(df_diff)
df_diff_ts <- ts(df_diff_xts, frequency = 52, start = c(2022, 9))
Expanding_means <- rollapply(df_diff_ts, width = seq_along(df_diff_ts), FUN = mean, align = "right")
Expanding_means <- as.numeric(Expanding_means)



# Create binary indicator variable
adj_holid2 <- df_diff %>%
  mutate(adjacent_holiday = sapply(Date, is_adjacent_holiday))
adj_holid2 <- adj_holid2 %>%
  select(adjacent_holiday)
adj_holid2 <- as.numeric(adj_holid2$adjacent_holiday)




#not enough data to capture long term trends I think
model_data_tbl2 <- df_diff %>% 
  mutate( # Rolling_mean_2 = rollmean(Zile, k = 2, fill = NA, align = "right"),
          # Rolling_mean_5 = rollmean(Zile, k = 5, fill = NA, align = "right"),
           Rolling_mean_7 = rollmean(diff, k = 7, fill = NA, align = "right"),
          Rolling_mean_9 = rollmean(diff, k = 9, fill = NA, align = "right"),
          Rolling_mean_13 = rollmean(diff, k = 13, fill = NA, align = "right"),
          # Rolling_mean_26 = rollmean(Zile, k = 26, fill = NA, align = "right"),
          # SD_2 = rollapply(Zile, width = 2, FUN = sd, fill = NA, align = "right"),
          # SD_5 = rollapply(Zile, width = 5, FUN = sd, fill = NA, align = "right"),
           SD_7 = rollapply(diff, width = 7, FUN = sd, fill = NA, align = "right"),
          SD_9 = rollapply(diff, width = 9, FUN = sd, fill = NA, align = "right"),
          SD_13 = rollapply(diff, width = 13, FUN = sd, fill = NA, align = "right"),
          # SD_26 = rollapply(Zile, width = 26, FUN = sd, fill = NA, align = "right"),
          Expanding_mean = Expanding_means,
          Rev_lag_1   = lag(diff, n = 1),
          Rev_lag_2   = lag(diff, n = 2),
          Rev_lag_3   = lag(diff, n = 3),
          Rev_lag_4  = lag(diff, n = 4),
          Rev_lag_5   = lag(diff, n = 5),
          Rev_lag_6   = lag(diff, n = 6),
          Rev_lag_7   = lag(diff, n = 7),
    # Rolling_mean_2_Lag_1 = Rolling_mean_2 * Rev_lag_1,
    # Rolling_mean_2_Lag_2 = Rolling_mean_2 * Rev_lag_2,
    # Rolling_mean_13_Lag_1 = Rolling_mean_13 * Rev_lag_1,
    # Rolling_mean_13_Lag_2 = Rolling_mean_13 * Rev_lag_2,
    # Rolling_mean_26_Lag_1 = Rolling_mean_26 * Rev_lag_1,
    # Rolling_mean_26_Lag_2 = Rolling_mean_26 * Rev_lag_2,
    # EMA_2 = EMA(Zile, n = 2),
    # EMA_5 = EMA(Zile, n = 5),
     EMA_7 = EMA(diff, n = 7),
    EMA_9 = EMA(diff, n = 9),
    EMA_13 = EMA(diff, n = 13),
    # DEMA_2 = DEMA(Zile, n = 2),
    # DEMA_5 = DEMA(Zile, n = 5),
     DEMA_7 = DEMA(diff, n = 7),
    DEMA_9 = DEMA(diff, n = 9),
    DEMA_13 = DEMA(diff, n = 13),
    # DEMA_26 = DEMA(Zile, n = 26),
    # WMA_2 = WMA(Zile, n = 2),
    # WMA_5 = WMA(Zile, n = 5),
     WMA_7 = WMA(diff, n = 7),
    WMA_9 = WMA(diff, n = 9),
    WMA_13 = WMA(diff, n = 13),
    # EMA_2_Lag_1 = EMA_2 * Rev_lag_1,
    # EMA_2_Lag_2 = EMA_2 * Rev_lag_2,
    # EMA_13_Lag_1 = EMA_13 * Rev_lag_1,
    # EMA_13_Lag_2 = EMA_13 * Rev_lag_2,
    # EMA_5_Lag_1 = EMA_5 * Rev_lag_1,
    # EMA_5_Lag_2 = EMA_5 * Rev_lag_2,
    # EMA_7_Lag_1 = EMA_7 * Rev_lag_1,
    # EMA_7_Lag_2 = EMA_7 * Rev_lag_2,
    # EMA_9_Lag_1 = EMA_9 * Rev_lag_1,
    # EMA_9_Lag_2 = EMA_9 * Rev_lag_2,
    #       month_january = as.numeric(lubridate::month(Date) == 1),
    # month_february = as.numeric(lubridate::month(Date) == 2),
    # month_march = as.numeric(lubridate::month(Date) == 3),
    # month_april = as.numeric(lubridate::month(Date) == 4),
    # month_may = as.numeric(lubridate::month(Date) == 5),
    # month_june = as.numeric(lubridate::month(Date) == 6),
    # month_july = as.numeric(lubridate::month(Date) == 7),
    # month_august = as.numeric(lubridate::month(Date) == 8),
    # month_september = as.numeric(lubridate::month(Date) == 9),
    # month_october = as.numeric(lubridate::month(Date) == 10),
    # month_november = as.numeric(lubridate::month(Date) == 11),
    # month_december = as.numeric(lubridate::month(Date) == 12),
    Month = lubridate::month(Date),
    Quarter = lubridate::quarter(Date),
     Year = lubridate::year(Date),
    Week_of_Year = isoweek(Date),
    Day_of_year = yday(Date),
    Outlier_indicator = as.numeric(diff < quantile(diff, 0.05) | diff > quantile(diff, 0.95)),
     Adjacent_holiday = adj_holid2
        ) %>% filter(!is.na(Rev_lag_1) & !is.na(Rev_lag_7)  & !is.na(SD_13)
           # !is.na(Rolling_mean_2) & !is.na(Rolling_mean_13)  & 
           )


test2 <- model_data_tbl2 %>% filter(Date >= ymd("2023-09-08"))
train2 <- model_data_tbl2 %>% filter(Date < ymd("2023-09-08"))


### Modelling
  
  #initiate h2o
  h2o.init(max_mem_size = "16G")
h2o.no_progress()

# response variable
y <- "diff"

# predictors set: remove response variable and date from the set
x <- setdiff(names(train2 %>% as.h2o()), c(y, "Date"))

DL_diff <-
  h2o.automl(
    x = x,
    y = y,
    training_frame     = as.h2o(train2),
    nfolds             = 0,
     validation_frame   = test2 %>% as.h2o(),
                    include_algos = c("DeepLearning"),
    stopping_metric    = "RMSE",
    stopping_rounds    = 10,
    stopping_tolerance = 0.005,
    max_runtime_secs   = 120,
    sort_metric       = "RMSE",
    seed               = 1975
 )
DL_diff_lead <- DL_diff@leader
perf_dl_test <- h2o.performance(DL_diff_lead, newdata = as.h2o(test2))
predictions <- as.vector(h2o.predict(DL_diff_lead, as.h2o(test2))$predict)
actual_values_diff <- as.data.frame(test2) %>%
  select(Date, diff)

actual_vs_predicted_diff <- cbind(actual_values_diff, DL = predictions) %>% dplyr::rename(Actual = diff)


plot_dif <-actual_vs_predicted_diff %>%
 plot_ly() %>% 
    add_lines(x = ~ Date, y = ~ Actual, name = 'Actual values', line = list(color = 'darkblue')) %>% 
    
    add_lines(x = ~ Date, y = ~ DL, name = 'Deep Learning', 
              line = list(dash = 'dot', color = 'red')) %>% 
     layout(
    title = list(text = '', font = list(size = 16, color = 'black')),
    yaxis = list(title = list(text = 'Nr. of days', font = list(size = 14, color = 'black'))),
    xaxis = list(title = list(text = ''), font = list(size = 14)),
    legend = list(orientation = 'h', font = list(size = 12))
  )
r_squared <- as.numeric(rsq_trad(actual_vs_predicted_diff, Actual, DL)$.estimate)
plot_cor_dif <- ggplotly(
  ggplot(actual_vs_predicted_diff, aes(x = Actual, y = DL)) +
  geom_point() +  # Point plot
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "darkred") +  # Dashed diagonal line
  labs(title = "",
       x = "Actual Values",
       y = "Predicted Values") + theme_tq() + scale_x_continuous(limits = c(-10, 10)) + scale_y_continuous(limits = c(-10, 10)) +  annotate("text", x = min(actual_vs_predicted_diff$Actual), y = max(actual_vs_predicted_diff$DL), 
           label = paste("R-squared =", round(r_squared, 3)), vjust = 1, hjust = 0)
)
```
